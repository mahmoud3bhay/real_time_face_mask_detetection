{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "T9EwC08pePRz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Flatten, GlobalAveragePooling2D\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"/content/drive/MyDrive/real time face mask detection /Dataset/train\"\n"
      ],
      "metadata": {
        "id": "GdiGh6AomTKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')"
      ],
      "metadata": {
        "id": "3PqgWKSDmcIZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                    batch_size=10, \n",
        "                                                    target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC6UtMh3mcPj",
        "outputId": "51e8bdfa-cc14-4672-f57e-59caf4eeb45d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1322 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_DIR = \"/content/drive/MyDrive/real time face mask detection /Dataset/test\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n"
      ],
      "metadata": {
        "id": "4Ch4ajVtmcVH"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
        "                                                         batch_size=10, \n",
        "                                                         target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtfvLjCpmurI",
        "outputId": "844a7698-9533-4ba2-cfe4-269fe35e42bb"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 194 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential([\n",
        "    Conv2D(120, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Conv2D(100, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Flatten(),\n",
        "    \n",
        "    Dense(80, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "x4IcRciHmzX5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "46NrUr3Am6oH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n"
      ],
      "metadata": {
        "id": "AQ6q4Ka1nZxM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict={0:'without mask',1:'mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}"
      ],
      "metadata": {
        "id": "DrhsOdPkvze9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "EFJo9PsNv2_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =Sequential([\n",
        "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Conv2D(100, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "svdY8yTbmOwV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "PXKh4TT3mQ6r"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n"
      ],
      "metadata": {
        "id": "hPseJ4iLmuti"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Lb27RdJxHE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              validation_data=validation_generator,\n",
        "                              callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUPRXfCxm9gP",
        "outputId": "6c891784-07aa-4cfc-be53-cdf51d72f6da"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-6272b23e5a0b>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.4815 - acc: 0.7678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r133/133 [==============================] - 190s 1s/step - loss: 0.4815 - acc: 0.7678 - val_loss: 0.2437 - val_acc: 0.9227\n",
            "Epoch 2/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.3161 - acc: 0.8790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r133/133 [==============================] - 220s 2s/step - loss: 0.3161 - acc: 0.8790 - val_loss: 0.1221 - val_acc: 0.9588\n",
            "Epoch 3/10\n",
            "133/133 [==============================] - 181s 1s/step - loss: 0.2945 - acc: 0.8828 - val_loss: 0.1949 - val_acc: 0.8969\n",
            "Epoch 4/10\n",
            "133/133 [==============================] - 184s 1s/step - loss: 0.2624 - acc: 0.9077 - val_loss: 0.1235 - val_acc: 0.9742\n",
            "Epoch 5/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.2571 - acc: 0.9168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r133/133 [==============================] - 181s 1s/step - loss: 0.2571 - acc: 0.9168 - val_loss: 0.1203 - val_acc: 0.9485\n",
            "Epoch 6/10\n",
            "133/133 [==============================] - ETA: 0s - loss: 0.2392 - acc: 0.9085"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r133/133 [==============================] - 177s 1s/step - loss: 0.2392 - acc: 0.9085 - val_loss: 0.0476 - val_acc: 0.9897\n",
            "Epoch 7/10\n",
            "133/133 [==============================] - 172s 1s/step - loss: 0.2575 - acc: 0.9032 - val_loss: 0.0629 - val_acc: 0.9742\n",
            "Epoch 8/10\n",
            "133/133 [==============================] - 180s 1s/step - loss: 0.2048 - acc: 0.9228 - val_loss: 0.1456 - val_acc: 0.9175\n",
            "Epoch 9/10\n",
            "133/133 [==============================] - 173s 1s/step - loss: 0.2361 - acc: 0.9153 - val_loss: 0.1866 - val_acc: 0.9072\n",
            "Epoch 10/10\n",
            "133/133 [==============================] - 176s 1s/step - loss: 0.1647 - acc: 0.9349 - val_loss: 0.0971 - val_acc: 0.9433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xK8gS-v3xnFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving model to my own device for later use without training "
      ],
      "metadata": {
        "id": "AbcUzdiroSJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/real time face mask detection/model2.h5')"
      ],
      "metadata": {
        "id": "wedDYw-1nF-N"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PY_hpWaWxHHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Vkz1C2NxHJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"D:/Computer vision/real_face_mask/model.h5\"\n"
      ],
      "metadata": {
        "id": "5dettSmwoaH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WA25cVuEmuwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model \n",
        "loded_model = load_model(model_name ,compile =False  )"
      ],
      "metadata": {
        "id": "LleC5u5voiK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMMY-iSVn_8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "QrpBOJh7oaOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = cv2.CascadeClassifier('C:/Users/FreeComp/Downloads/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "exN_bZtAn1y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict={0:'without mask',1:'mask'}\n",
        "color_dict={0:(0,0,255),1:(0,255,0)}\n",
        "\n",
        "size = 4\n",
        "webcam = cv2.VideoCapture(0) #Use camera 0"
      ],
      "metadata": {
        "id": "3tRXFZzcoiRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    (rval, im) = webcam.read()\n",
        "    im=cv2.flip(im,1,1) #Flip to act as a mirror\n",
        "\n",
        "    # Resize the image to speed up detection\n",
        "    mini = cv2.resize(im, (im.shape[1] // size, im.shape[0] // size))\n",
        "\n",
        "    # detect MultiScale / faces \n",
        "    faces = classifier.detectMultiScale(mini)\n",
        "\n",
        "    # Draw rectangles around each face\n",
        "    for f in faces:\n",
        "        (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup\n",
        "        #Save just the rectangle faces in SubRecFaces\n",
        "        face_img = im[y:y+h, x:x+w]\n",
        "        resized=cv2.resize(face_img,(150,150))\n",
        "        normalized=resized/255.0\n",
        "        reshaped=np.reshape(normalized,(1,150,150,3))\n",
        "        reshaped = np.vstack([reshaped])\n",
        "        result=loded_model.predict(reshaped)\n",
        "        #print(result)\n",
        "        \n",
        "        label=np.argmax(result,axis=1)[0]\n",
        "      \n",
        "        cv2.rectangle(im,(x,y),(x+w,y+h),color_dict[label],2)\n",
        "        cv2.rectangle(im,(x,y-40),(x+w,y),color_dict[label],-1)\n",
        "        cv2.putText(im, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
        "        \n",
        "    # Show the image\n",
        "    cv2.imshow('LIVE',   im)\n",
        "    key = cv2.waitKey(10)\n",
        "    # if Esc key is press then break out of the loop \n",
        "    if key == 27: #The Esc key\n",
        "        break\n",
        "# Stop video\n",
        "webcam.release()\n",
        "\n",
        "# Close all started windows\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5cd3nTfaonp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGoYD4s_onsg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}